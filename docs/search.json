[
  {
    "objectID": "HumanFreedomIndex.html",
    "href": "HumanFreedomIndex.html",
    "title": "4  High Dimensional Data Example with Human Freedom Index",
    "section": "",
    "text": "The techniques in this demonstration utilize the glmnet package to fit the regularized models. More information about this package can be found at (“An Introduction to ‘Glmnet‘” 2021)\nFor this demonstration, the political freedom homicide variable will be the response variable. Each of the other distinct variables (excluding indexes and total scores) will be used as predictors.\n\n\n\n\n4.0.1 Trimming and Fitting a Linear Model\n\n#Human Freedom Index Linear Model\nfreedomData <- hfi\nfreedomData <- freedomData %>% filter(year==2016)%>% select(c(-\"year\",-\"ISO_code\",-\"countries\",-\"region\",-\"ef_score\",-\"ef_rank\",-\"hf_rank\",-\"hf_quartile\",-\"pf_score\",-\"pf_rank\",-\"pf_religion_estop_establish\",-\"pf_religion_estop_operate\",-\"pf_identity_legal\",-\"pf_rol_procedural\",-\"pf_rol_civil\",-\"pf_rol_criminal\",-\"pf_ss_women_inheritance_widows\",-\"pf_ss_women_inheritance_daughters\",-\"pf_association_political_establish\",-\"pf_association_political_operate\",-\"pf_association_sport_operate\",-\"pf_association_sport_establish\",-\"pf_identity_divorce\",-\"pf_association_prof_operate\",-\"pf_association_prof_establish\"))%>%mutate(id = row_number())\n#check missing data values\nfreedomData <- na.omit(freedomData) \ntrain <- freedomData %>% sample_frac(.8)\ntest <- anti_join(freedomData, train, by='id')\n\nytrain <- train$pf_ss_homicide\nytest <- test$pf_ss_homicide\nxtrainLin <- train %>% select(c(-\"id\"))\nxtrain <- train %>% select(c(-\"pf_ss_homicide\",-\"id\"))\nxtestLin <- test %>% select(c(-\"id\"))\nxtest <- test %>% select(c(-\"pf_ss_homicide\",-\"id\"))\n\nxtestFrame <- xtest\nxtest <- data.matrix(xtest)\npredictors <- data.matrix(xtrain)\nresp <- ytrain\n\nlinModel <- lm(pf_ss_homicide~., data=xtrainLin)\n\n \nThe figures above the show the outcome of trying to fit a traditional linear model to the data as it is. The model is not workable due to a lack of degrees of freedom to fit the number of predictors in the data set. In this case, the number of predictors could be trimmed at random to get a working model, but the regularization techniques can be used to evaluate this data set without randomly choosing predictors.\nTo fit the regularization models, the glmnet function will be used. The CV.glmnet function below performs a cross-fold validation on the training data in order to obtain the optimal lambda value for the respective model. In this function, the value of alpha controls the form of regularization that will be applied. An alpha value of 1 corresponds to LASSO regression, a value of 0 corresponds to Ridge Regression, and a value in between corresponds to a form of Elastic Net Regularization. The magnitude of alpha controls the penalty term in the Elastic Net Regularization. As in most regularization problems, the value of the penalty term (in this case lambda) is of critical importance.\n\n\n4.0.2 Fitting Regularized Models\nEach method will have a model fit. These will then have their RSquare and RMSE scores displayed to show a relative performance for each method.\nThe basic code structure is as follows:\n\nPerform Cross Validation to acquire the optimal lambda. The alpha term is altered based on the method.\nPass the optimal lambda into a new model based on the training data.\nExamine the impact on the coefficients.\nUsing the model, make predictions on the training data and the test data.\nStore results and display scores for each method.\n\n\nset.seed(250)\n#LASSO\nmodelResults <- data.frame(matrix(ncol=6,nrow=0))\ncolnames(modelResults)<-c(\"Model\",\"Train_RSquare\",\"Train_RMSE\",\"Test_RSquare\",\"Test_RMSE\",\"CoefficientCount\")\n\nmodel <- cv.glmnet(predictors, resp, alpha=1)\nbestLambda <- model$lambda.min\n#Optimal Lambda has been fit.\nplot(model)\n\n\n\n\nThe LASSO Lambda plot demonstrates the MSE for different values of lambda.\n\nfinalModel <- glmnet(predictors,resp, alpha=1, lambda=bestLambda)\ncoefTable <- coefficients(finalModel)\ncoefList <- data.frame(matrix(ncol=2,nrow=0))\ncolnames(coefList)<-c(\"Predictor\",\"Coefficient\")\n\nfor(x in 1:nrow(coefTable)){\n if(coefTable[x,1] != 0)\n {rows <- nrow(coefList)\n predNames <- data.frame(coefTable@Dimnames)\n   newRow <- c(predNames[x,1],coefTable[x,1])\n    coefList[rows+1,] <- newRow    \n   } \n}\n\nfinalModelPredict <- predict(finalModel, s= bestLambda, newx = predictors)\nfinalModelTest <- predict(finalModel, s= bestLambda, newx = xtest)\nrows<-nrow(modelResults)\nnewRow <- c(\"LASSO\",eval_results(resp,finalModelPredict,freedomData)$Rsquare,eval_results(resp,finalModelPredict,freedomData)$RMSE,eval_results(ytest,finalModelTest,freedomData)$Rsquare,eval_results(ytest,finalModelTest,freedomData)$RMSE, count(coefList))\nmodelResults[rows+1,]<-newRow\nLASSOCoef <- coefList\n\n\n#Ridge\nmodel <- cv.glmnet(predictors, resp, alpha=0)\nbestLambda <- model$lambda.min\n#Optimal Lambda has been fit.\nplot(model)\n\n\n\n\nThe Ridge Regression plot shows higher values of lambda. For Ridge Regression, the choice of lambda represents a factor of shrinkage. A lambda of 0 would be equivalent to normal linear regression while a very high lambda would shrink all coefficients towards 0.\n\nfinalModel <- glmnet(predictors,resp, alpha=0, lambda=bestLambda)\ncoefTable <- coefficients(finalModel)\ncoefList <- data.frame(matrix(ncol=2,nrow=0))\ncolnames(coefList)<-c(\"Predictor\",\"Coefficient\")\n\nfor(x in 1:nrow(coefTable)){\n if(coefTable[x,1] != 0)\n {rows <- nrow(coefList)\n predNames <- data.frame(coefTable@Dimnames)\n   newRow <- c(predNames[x,1],coefTable[x,1])\n    coefList[rows+1,] <- newRow    \n   } \n}\n\nfinalModelPredict <- predict(finalModel, s= bestLambda, newx = predictors)\nfinalModelTest <- predict(finalModel, s= bestLambda, newx = xtest)\nrows<-nrow(modelResults)\nnewRow <- c(\"Ridge\",eval_results(resp,finalModelPredict,freedomData)$Rsquare,eval_results(resp,finalModelPredict,freedomData)$RMSE,eval_results(ytest,finalModelTest,freedomData)$Rsquare,eval_results(ytest,finalModelTest,freedomData)$RMSE, count(coefList))\nmodelResults[rows+1,]<-newRow\n\nThree different models using elastic net will now be fit with different increments of alpha.\n\n#Elastic Net 1\nmodel <- cv.glmnet(predictors, resp, alpha=.25)\nbestLambda <- model$lambda.min\n#Optimal Lambda has been fit.\n\n\nfinalModel <- glmnet(predictors,resp, alpha=.25, lambda=bestLambda)\ncoefTable <- coefficients(finalModel)\ncoefList <- data.frame(matrix(ncol=2,nrow=0))\ncolnames(coefList)<-c(\"Predictor\",\"Coefficient\")\n\nfor(x in 1:nrow(coefTable)){\n if(coefTable[x,1] != 0)\n {rows <- nrow(coefList)\n predNames <- data.frame(coefTable@Dimnames)\n   newRow <- c(predNames[x,1],coefTable[x,1])\n    coefList[rows+1,] <- newRow    \n   } \n}\n\nfinalModelPredict <- predict(finalModel, s= bestLambda, newx = predictors)\nfinalModelTest <- predict(finalModel, s= bestLambda, newx = xtest)\nrows<-nrow(modelResults)\nnewRow <- c(\"ENet.25\",eval_results(resp,finalModelPredict,freedomData)$Rsquare,eval_results(resp,finalModelPredict,freedomData)$RMSE,eval_results(ytest,finalModelTest,freedomData)$Rsquare,eval_results(ytest,finalModelTest,freedomData)$RMSE, count(coefList))\nmodelResults[rows+1,]<-newRow\n\n\n#Elastic Net 2\nmodel <- cv.glmnet(predictors, resp, alpha=.5)\nbestLambda <- model$lambda.min\n#Optimal Lambda has been fit.\n\n\nfinalModel <- glmnet(predictors,resp, alpha=.5, lambda=bestLambda)\ncoefTable <- coefficients(finalModel)\ncoefList <- data.frame(matrix(ncol=2,nrow=0))\ncolnames(coefList)<-c(\"Predictor\",\"Coefficient\")\n\nfor(x in 1:nrow(coefTable)){\n if(coefTable[x,1] != 0)\n {rows <- nrow(coefList)\n predNames <- data.frame(coefTable@Dimnames)\n   newRow <- c(predNames[x,1],coefTable[x,1])\n    coefList[rows+1,] <- newRow    \n   } \n}\n\nfinalModelPredict <- predict(finalModel, s= bestLambda, newx = predictors)\nfinalModelTest <- predict(finalModel, s= bestLambda, newx = xtest)\nrows<-nrow(modelResults)\nnewRow <- c(\"ENet.50\",eval_results(resp,finalModelPredict,freedomData)$Rsquare,eval_results(resp,finalModelPredict,freedomData)$RMSE,eval_results(ytest,finalModelTest,freedomData)$Rsquare,eval_results(ytest,finalModelTest,freedomData)$RMSE, count(coefList))\nmodelResults[rows+1,]<-newRow\n\n#Elastic Net 3\nmodel <- cv.glmnet(predictors, resp, alpha=.75)\nbestLambda <- model$lambda.min\n#Optimal Lambda has been fit.\n\n\nfinalModel <- glmnet(predictors,resp, alpha=.75, lambda=bestLambda)\ncoefTable <- coefficients(finalModel)\ncoefList <- data.frame(matrix(ncol=2,nrow=0))\ncolnames(coefList)<-c(\"Predictor\",\"Coefficient\")\n\nfor(x in 1:nrow(coefTable)){\n if(coefTable[x,1] != 0)\n {rows <- nrow(coefList)\n predNames <- data.frame(coefTable@Dimnames)\n   newRow <- c(predNames[x,1],coefTable[x,1])\n    coefList[rows+1,] <- newRow    \n   } \n}\n\nfinalModelPredict <- predict(finalModel, s= bestLambda, newx = predictors)\nfinalModelTest <- predict(finalModel, s= bestLambda, newx = xtest)\nrows<-nrow(modelResults)\nnewRow <- c(\"ENet.75\",eval_results(resp,finalModelPredict,freedomData)$Rsquare,eval_results(resp,finalModelPredict,freedomData)$RMSE,eval_results(ytest,finalModelTest,freedomData)$Rsquare,eval_results(ytest,finalModelTest,freedomData)$RMSE, count(coefList))\nmodelResults[rows+1,]<-newRow\n\n\n\n4.0.3 Regularization Results / Discussion\nThe final model group looks like the table below.\n\nprint(modelResults)\n\n    Model Train_RSquare Train_RMSE Test_RSquare  Test_RMSE CoefficientCount\n1   LASSO     0.9990511 0.08008846    0.9950947 0.04108366               10\n2   Ridge     0.5450998 1.75353709   -0.5939997 0.74059439               98\n3 ENet.25     0.9882959 0.28127156    0.7864316 0.27108457               41\n4 ENet.50     0.9961357 0.16161849    0.9609997 0.11584308               29\n5 ENet.75     0.9984550 0.10219152    0.9891886 0.06099273               16\n\n\nThe number of coefficients selected by each individual method corresponds to how “LASSO” like or “Ridge” like the alpha parameter was set. The pure LASSO regression shows that 13 predictors were selected, while the pure Ridge Regression shows all 98 possible predictors were chosen. The Elastic Net models fall somewhere between, depending on the strength of the alpha parameter.\nThe LASSO selected features included:\n\nprint(LASSOCoef)\n\n                         Predictor          Coefficient\n1                      (Intercept)    0.164150921470556\n2  pf_ss_disappearances_fatalities  -0.0129599840888325\n3             pf_ss_disappearances   -0.911528662640944\n4                      pf_ss_women   -0.950530917505778\n5                            pf_ss     2.83919637198405\n6           pf_religion_harassment  -0.0157775109361049\n7                      pf_religion -0.00652056877913663\n8     pf_identity_parental_divorce -0.00172583747026147\n9                   ef_legal_crime   0.0520227929733391\n10         ef_trade_movement_visit -0.00153108537147748\n\n\nThe model with the best fit in this case was the pure LASSO model. As has been shown, this regression model can be used for predictions. More refinement can be performed. For example, in this case, there is still the likelihood that the model is overfit since 13 predictors is still a large number when compared to 93 observations. To further understand this is a matter of the underlying mechanics in the data. It is also possible that these 13 predictors still have some manner of collinearity present. Regularization, in this case, has now given a workable group of features to analyze for a refined linear model.\n\n\n\n\n“An Introduction to ‘Glmnet‘.” 2021. stanford.edu. https://glmnet.stanford.edu/articles/glmnet.html."
  }
]