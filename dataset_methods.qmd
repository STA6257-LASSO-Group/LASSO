# Methods and Materials

## Data sets

Previous studies indicate LASSO regression outperforms Ridge regression with sparse data sets in which the variable size is larger than the sample size. Conversely, Ridge regression has been shown to outperform LASSO regression with dense data in which the variable size is smaller than the sample size.[@JamesTib21] The hybrid of the two, Elastic Net regression, will adapt to either type of data by using the properties of LASSO and Ridge regression together. We aim to use two data sets with different characteristics to highlight the advantages of each of the three linear regularization techniques while also using these statistical methods to model the data and make predictions.

### Human Freedom Index

The Human Freedom Index from the openintro R package will be used to demonstrate regularization in a high dimensional example where the number of predictors is greater than the number of observations. This data consists of sociological measures of the different types of freedom. The main dataset has 1458 observations with 123 variables, but for this example, a single year of complete observations will be used. This results in a dataset of 93 observations across 99 variables and mimics the situation that would occur if a researcher attempted to analyze the most recent year of this data in isolation from the rest of the dataset.

Aside from year, country, and region identifiers, each column in this data set is a continuous numerical variable. Some variables have high degrees of collinearity because of their relation to one another. For example, total disappearances is expected to have high collinearity with total violent disappearances.

### Jackson Heart Study

The Jackson Heart Study (JHS) data has 198 variables and an n of 2653 for Visit 1 (out of 3). The JHS data will be used to highlight Ridge regression's performance over LASSO's when the sample size greatly outnumbers the variable size. Additionally, we are interested in using this data set to test all three methods on shrinking the multicollinearity and to test LASSO's feature selection capabilities.

### Programmatic Tools, Statistical Methods, and Code Packages

RStudio is the primary IDE used to run the demonstrations of these methods. The R Language is the coding language used. To deal with missing values in the multicollinearity example, the missing values are imputed using the MICE (Multiple Imputation by Chained Equations) algorithm. This algorithm is able to determine appropriate values for missing data by using the other variables in the dataset to converge upon a satisfactory value. Since collinearity is an important aspect of the regularization problem, correlation plots will be used to visually showcase collinearity among variables where appropriate. The ones being used take the form of heat-maps where bright red color indicates high positive correlation and dark blue color indicates high negative correlation. [@mice]
In addition, at the end of each demonstration, the R-squared and Root Mean Square Error will be calculated for the models run. The R-squared measures the among of predicted variable variance that is explained by the model while the error represents the standard deviation of the residuals. The Variance Inflation Factor (VIF) will be calculated in the multicollinearity example as it is a quantifier for how strong the multicollinearity effect is between variables. We will also be examining the difference between variable significance and importance where variable importance represents the amount of information a given predictor adds to the model and significance corresponds to whether or not a given predictor is explaining the random variation in a dependent variable.
The primary code packages used to perform the Regularized Regression analyses will be two R packages: glmnet and caret. The glmnet package was developed at Stanford University by Trevor Hastie, Junyang Qian, and Kenneth Tay. It is designed to fit penalized generalized models and is able to calculate for the parameter lambda in an algorithmic approach (as opposed to having to provide a matrix of potential lambda variables). It is able to fit multiple regression situations, and, as such, has cross functional application beyond just the traditional linear LASSO regression implementation. In its arguments, this package can also be used to fit some of the extensions to LASSO such as relaxed LASSO. [@glmnet]
Caret, by contrast, is a general classification and regression model package used in R. It is used for building models for a variety of problems, including generalized regression situations. In addition to regression problems, caret also contains methods for easily splitting test data, training models, and making predictions. [@caret]



