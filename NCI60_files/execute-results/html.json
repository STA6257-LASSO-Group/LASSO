{
  "hash": "acae456919d0df12154c1746e37abc6e",
  "result": {
    "markdown": "## High Dimensional Data Example\n\nThe NCI 60 data consists of expression levels from 6830 genes from 64 different cancer cell lines. We want to create a model predicting the gene expression level of gene 1 using the 6829 other genes as predictors. Because this is a problem where the number of predictors is far greater than the number of observations, regular least squares regression will not be applicable, so a regularized regression method will be used.\n\nIn this dataset, the data is already standardized.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](NCI60_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\nThe graph above shows the distribution of the gene expression level being examined.\n\n### Calculating Model Using LASSO\n\nIn computing a LASSO solution to a problem, a main point of concern is the calculation of the Lambda term. In the overview section above, the lambda term was discussed as being the penalty term for the regularization. There are several R packages used to calculate Lambda in a LASSO problem. In this high dimensional example, the glmnet package will be used to estimate the optimal lambda value for the data and to generate the final model. The point of this example is to demonstrate the LASSO effect of reducing the dimensionality of a high dimensional example.\n\nThe cv.glmnet function uses cross-fold validation to generate LASSO regression models for the gene dataset. It outputs a series of models, each with its own lambda value. The model with the minimal lambda value is the one used for the final fitted model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(250)\n#Create model using cross fold validation and glmnet. \nmodel <- cv.glmnet(predictors, resp, alpha=1)\nbestLambda <- model$lambda.min\nplot(model)\n```\n\n::: {.cell-output-display}\n![](NCI60_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nThe plot above shows the change in MSE for the different models compared to their lambda values. The optimal lambda value calculated was 0.1263351\n\nNow that the optimal lambda has been chosen, the final model will be fit to the data and the output coefficients from the 6829 original coefficients will be displayed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinalModel <- glmnet(predictors,resp, alpha=1, lambda=bestLambda)\ncoefTable <- coefficients(finalModel)\ncoefList <- data.frame(matrix(ncol=2,nrow=0))\ncolnames(coefList)<-c(\"Gene Number\",\"Coefficient\")\n\nfor(x in 1:nrow(coefTable)){\n if(coefTable[x,1] > 0)\n {rows <- nrow(coefList)\n   newRow <- c(x,coefTable[x,1])\n    coefList[rows+1,] <- newRow    \n   } \n}\n\nfinalModelPredict <- predict(finalModel, s= bestLambda, newx = predictors)\nprint(coefList)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Gene Number Coefficient\n1        3936 0.007314000\n2        3995 0.045146244\n3        4818 0.066865827\n4        5435 0.005142151\n5        6262 0.008561928\n6        6576 0.019084629\n7        6609 0.114305087\n```\n:::\n\n```{.r .cell-code}\neval_results(resp,finalModelPredict,geneTable)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       RMSE   Rsquare\n1 0.3271616 0.4417445\n```\n:::\n:::\n\n\nIn the final model, the 6829 original gene expression levels have been reduced down to 6 different genes that the LASSO algorithm identified as having a large impact on gene 1's expression level.\n",
    "supporting": [
      "NCI60_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}